{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to use\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras as kr\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=np.genfromtxt('iris.csv',delimiter=',',dtype='str',header=None)\n",
    "data=list(csv.reader(open('iris.csv')))[1:]\n",
    "#list(data)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs array with details and convert it from str to float\n",
    "inputs  = np.array(data)[:,:4].astype(np.float)\n",
    "# Create outputs array with species \n",
    "outputs = np.array(data)[:,4]\n",
    "#list(inputs)\n",
    "#list(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference to spilt data [keras-iris] (https://github.com/emerging-technologies/keras-iris/blob/master/iris_nn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_inverse——https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.unique.html\n",
    "# return the indices of the unique array ——each species gets a unique index in different position to represent their value \n",
    "outputs_vals, outputs_ints = np.unique(outputs, return_inverse=True)\n",
    "\n",
    "# import this package to change type of index for next step that can match outputs data format \n",
    "from keras.utils import np_utils\n",
    "outputs_cats = kr.utils.to_categorical(outputs_ints)\n",
    "\n",
    "#print(outputs_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the input and output data sets into training and test subsets.\n",
    "# np.random.permutation——https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.permutation.html\n",
    "# randomly  shuffle the elements of array\n",
    "\n",
    "\n",
    "inds = np.random.permutation(len(inputs))\n",
    "\n",
    "# make multiple sub-arrays to split data 75 by 75\n",
    "train_inds, test_inds = np.array_split(inds, 2)\n",
    "\n",
    "# match array of value to input and output type\n",
    "inputs_train, outputs_train = inputs[train_inds], outputs_cats[train_inds]\n",
    "inputs_test,  outputs_test  = inputs[test_inds],  outputs_cats[test_inds]\n",
    "#print(outputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders and variables. input has 4 features and output has 3 classes\n",
    "# x for inputs details and it can be fed data as same format\n",
    "x=tf.placeholder(tf.float32,shape=[None,4])\n",
    "# y for outputs details and it can be fed data as same format\n",
    "y=tf.placeholder(tf.float32,shape=[None,3])\n",
    "# Weight and bias\n",
    "W=tf.Variable(tf.zeros([4,3]))\n",
    "b=tf.Variable(tf.zeros([3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model of softmax to predict results\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy function to calculate the cross entropy\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimiser to train\n",
    "train_step = tf.train.AdamOptimizer(0.2).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "# Number of interations\n",
    "    for epoch in range(50):\n",
    "        c=sess.run([train_step], feed_dict={x: inputs_train, y:outputs_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating accuracy of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0,Testing Result 0.306667,Testing Error Rate 0.69333332777\n",
      "Result 5,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 10,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 15,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 20,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 25,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 30,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 35,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 40,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 45,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 50,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 55,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 60,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 65,Testing Result 0.653333,Testing Error Rate 0.346666693687\n",
      "Result 70,Testing Result 0.653333,Testing Error Rate 0.346666693687\n"
     ]
    }
   ],
   "source": [
    "# tf.equal to decide what value should be returned (True is 1,False is 0) \n",
    "correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "# accuracy gets a average result of correct_prediction\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Test\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # times for training all training)set\n",
    "    for epoch in range(75):    \n",
    "        #train  \n",
    "        sess.run(train_step,{x:inputs_train, y:outputs_train})                  \n",
    "        #test\n",
    "        acc = sess.run(accuracy,{x:inputs_test, y:outputs_test})               \n",
    "        if(epoch%5==0):\n",
    "            print(\"Result \" + str(epoch) + \",Testing Result \" + str(acc) + \",Testing Error Rate \" + str(1-acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Accurency has some problems that all of them get same result "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
